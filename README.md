# vsn_rr
Evaluation of Visual Semantic Navigation Models in Real Robots

We are glad to introduce a novel ROS-based framework for Visual Semantic Navigation (VSN), designed to simplify the 
deployment of VSN models on any ROS-compatible robot and tested in the real world. The next figure shows how these VSN model work when deployed on our robotic platforms. 

<img src="imgs/abstract.png" width="800">

The ROS framework we present is composed of two main packages:
1. visual_semantic_navigation (vsn)
2. discrete_move

## visual_semantic_navigation (vsn) package
The [vsn](catkin_ws/src/vsn) Package is designed to deploy artificial intelligence models capable of autonomous navigation. 
This package is a client that interacts with the  [discrete_move](catkin_ws/src/discrete_move) package, 
which is responsible for performing the discrete movements inferred by the AI model.

Additionally, This package contains two submodules:
* [Image_preprocessing](catkin_ws/src/vsn/scripts/image_preprocessing.py) that is responsible for connecting to the camera via ROS topic and returning an RGB or RGB+D image in the form of a NumPy array.
* [Odometry](catkin_ws/src/vsn/scripts/odometry.py) that return the odometry value of the robot in case it needs to be used in the IA model. 

In summary, VSN package is designed to be a template that can be easily customized to deploy any AI model. 
By using the discrete_move service, the robot can execute the movements generated by the model in a precise and controlled manner.


## discrete_move package
This ROS package is designed to control the Lola Robot through parameterized movements, allowing the user
to specify the distance and angle of each movement. The package supports four possible movements:
  * **Forward**
  * **Backward**
  * **Turn left**
  * **Turn right**

The forward and backward movements can be controlled by specifying the distance that the robot needs to travel, 
while the turn left and turn right movements can be parameterized with the exact angle of movement required.

Furthermore, a ROS server has been designed to enable other ROS packages to connect as clients and execute parameterized discrete movements.

In summary, this ROS package provides a powerful tool for controlling the Lola Robot with a high degree of  precision, 
making it an excellent choice for a wide range of applications.

## Deploy the project with 

1. Install The Turtlebot2 package installation on ROS noetic. We have created a [script](scripts/install_turtlebot.sh) to install it. 

2. Install camera ROS-compatible with ROS. In our case, we have created a [script](scripts/install_camera.sh). 

3. In order to make compatible our packages with turtlebot you have to write the following line at the start of the *minimal.launch* file in ros package **turtlebot**.

```
<remap from="mobile_base/commands/velocity" to="cmd_vel"/>
```

4. 


We need the source to be pointing to the turtlebot_ws in order to install turtlebot packages and orbecc astra packages at lola
